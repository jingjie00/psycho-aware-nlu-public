{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas pickle file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "def extract(path):\n",
    "    print(os.getcwd())\n",
    "    file = open(path, 'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    file.close()\n",
    "    return object_file\n",
    "\n",
    "def save_dataset(item, dir, name):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    path = dir+\"/\"+name+\".pickle\"\n",
    "    pickle.dump(item, open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 2/2 [00:00<00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ENFP      ENTJ      INFJ      ENFJ      ISFJ      ENTP      ISFP  \\\n",
      "0  0.291670  0.239024  0.199571  0.068912  0.060027  0.037044  0.031224   \n",
      "1  0.008041  0.059717  0.018833  0.002206  0.012591  0.413074  0.015419   \n",
      "\n",
      "       ESFJ      INFP      ESTJ      ESFP      ISTJ      INTJ      ESTP  \\\n",
      "0  0.022395  0.015866  0.015733  0.014663  0.001525  0.001282  0.000503   \n",
      "1  0.001411  0.005133  0.264850  0.000103  0.000252  0.124362  0.022159   \n",
      "\n",
      "       ISTP      INTP highest  \n",
      "0  0.000377  0.000184    ENFP  \n",
      "1  0.018450  0.033400    ENTP  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"JanSt/albert-base-v2_mbti-classification\",top_k=None, max_length=512)\n",
    "\n",
    "def convert_list_to_dict(list_of_dicts):\n",
    "    result_dict = {}\n",
    "    for item in list_of_dicts:\n",
    "        label = item.get(\"label\")\n",
    "        score = item.get(\"score\")\n",
    "        if label is not None and score is not None:\n",
    "            result_dict[label] = score\n",
    "    return result_dict\n",
    "\n",
    "def convert_mbti_list(sentences):\n",
    "    # Assuming classifier and convert_list_to_dict are defined elsewhere\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Process each sentence in the list\n",
    "    for sentence in tqdm(sentences):\n",
    "        emo = classifier(sentence)  # Assuming classifier returns emotions for a single sentence\n",
    "        out = convert_list_to_dict(emo[0])  # Assuming convert_list_to_dict processes the emotion list\n",
    "        df = pd.DataFrame(out, index=[0])\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate the list of DataFrames into a single DataFrame\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    max_column = result_df.idxmax(axis=1)\n",
    "\n",
    "    # Add a new column to the DataFrame with the column name of the maximum value\n",
    "    result_df['highest'] = max_column\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(convert_mbti_list([\"I am happy\",\"he\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [2:23:11<00:00,  5.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "imdb = pd.read_csv('../../corpus/imdb.csv')\n",
    "imdb['sentiment'] = imdb['sentiment'].replace('positive', 1)\n",
    "imdb['sentiment'] = imdb['sentiment'].replace('negative', 0)\n",
    "sentence_list = imdb['review'].tolist()\n",
    "mbti_df_list = convert_mbti_list(sentence_list)\n",
    "imdb_ready = pd.concat([imdb, mbti_df_list], axis=1)\n",
    "imdb_ready.head()\n",
    "save_dataset(imdb_ready, \"../../corpus/personality-aware-sentiment\", \"albert-base-list-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_highest_list_ready = pd.concat([imdb['review'], mbti_df_list[\"highest\"]], axis=1)\n",
    "imdb_highest_list_ready['E'] = imdb_highest_list_ready['highest'].str.contains('E').astype(int)\n",
    "imdb_highest_list_ready['F'] = imdb_highest_list_ready['highest'].str.contains('F').astype(int)\n",
    "imdb_highest_list_ready['N'] = imdb_highest_list_ready['highest'].str.contains('N').astype(int)\n",
    "imdb_highest_list_ready['J'] = imdb_highest_list_ready['highest'].str.contains('J').astype(int)\n",
    "imdb_highest_list_ready.drop(\"highest\", axis=1, inplace=True)\n",
    "save_dataset(imdb_highest_list_ready, \"../../corpus/personality-aware-sentiment\", \"albert-base-highest-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [06:37<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "moviereview = pd.read_csv('../../corpus/movie-review.csv')\n",
    "sentence_list = moviereview['content'].tolist()\n",
    "mbti_df_list = convert_mbti_list(sentence_list)\n",
    "moviereview_ready = pd.concat([moviereview, mbti_df_list], axis=1)\n",
    "moviereview_ready.head()\n",
    "save_dataset(moviereview_ready, \"../../corpus/personality-aware-sentiment\", \"albert-base-list-moviereview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviereview_highest_list_ready = pd.concat([moviereview_ready['content'], mbti_df_list[\"highest\"]], axis=1)\n",
    "moviereview_highest_list_ready['E'] = moviereview_highest_list_ready['highest'].str.contains('E').astype(int)\n",
    "moviereview_highest_list_ready['F'] = moviereview_highest_list_ready['highest'].str.contains('F').astype(int)\n",
    "moviereview_highest_list_ready['N'] = moviereview_highest_list_ready['highest'].str.contains('N').astype(int)\n",
    "moviereview_highest_list_ready['J'] = moviereview_highest_list_ready['highest'].str.contains('J').astype(int)\n",
    "moviereview_highest_list_ready.drop(\"highest\", axis=1, inplace=True)\n",
    "save_dataset(moviereview_highest_list_ready, \"../../corpus/personality-aware-sentiment\", \"albert-base-highest-moviereview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "moviereview_highest_list_ready  = pickle.load(open(\"../../corpus/personality-aware-sentiment/albert-base-list-moviereview.pickle\", \"rb\"))\n",
    "moviereview_highest_list_ready = moviereview_highest_list_ready[['content', 'highest', 'label']]\n",
    "save_dataset(moviereview_highest_list_ready, \"../../corpus/personality-aware-sentiment\", \"albert-base-highest-moviereview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1895/1895 [02:49<00:00, 11.18it/s]\n"
     ]
    }
   ],
   "source": [
    "sdcnl = pd.read_csv('../../corpus/sdcnl.csv')\n",
    "\n",
    "# merge title and selftext column together, both have string value\n",
    "sdcnl['text'] = sdcnl['title'].astype(str) + \" | \" + sdcnl['selftext'].astype(str)\n",
    "\n",
    "# drop all column except text and is_suicide column\n",
    "sdcnl = sdcnl[['text', 'is_suicide']]\n",
    "\n",
    "sdcnl.head()\n",
    "\n",
    "sentence_list = sdcnl['text'].tolist()\n",
    "mbti_df_list = convert_mbti_list(sentence_list)\n",
    "sdcnl_ready = pd.concat([sdcnl, mbti_df_list], axis=1)\n",
    "sdcnl_ready.head()\n",
    "save_dataset(sdcnl_ready, \"../../corpus/personality-aware-depression\", \"albert-base-list-sdcnl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcnl_highest_list_ready = pd.concat([sdcnl_ready['text'], mbti_df_list[\"highest\"]], axis=1)\n",
    "sdcnl_highest_list_ready['E'] = sdcnl_highest_list_ready['highest'].str.contains('E').astype(int)\n",
    "sdcnl_highest_list_ready['F'] = sdcnl_highest_list_ready['highest'].str.contains('F').astype(int)\n",
    "sdcnl_highest_list_ready['N'] = sdcnl_highest_list_ready['highest'].str.contains('N').astype(int)\n",
    "sdcnl_highest_list_ready['J'] = sdcnl_highest_list_ready['highest'].str.contains('J').astype(int)\n",
    "sdcnl_highest_list_ready.drop(\"highest\", axis=1, inplace=True)\n",
    "save_dataset(sdcnl_highest_list_ready, \"../../corpus/personality-aware-depression\", \"albert-base-highest-sdcnl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>highest</th>\n",
       "      <th>is_suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need help | Hi I don't really know how to phra...</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feeling so overwhelmed and hopeless | i have b...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nothing matters anymore, getting worse | Hi..I...</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who’s tired of hearing bullshit | The shit lik...</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wish I was someone else. | I wish I was pret...</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text highest  is_suicide\n",
       "0  Need help | Hi I don't really know how to phra...    ENFP           0\n",
       "1  feeling so overwhelmed and hopeless | i have b...    INFP           1\n",
       "2  Nothing matters anymore, getting worse | Hi..I...    ESTJ           0\n",
       "3  Who’s tired of hearing bullshit | The shit lik...    ENTJ           1\n",
       "4  I wish I was someone else. | I wish I was pret...    ISFP           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "sdcnl_highest_list_ready = pickle.load(open(\"../../corpus/personality-aware-depression/albert-base-list-sdcnl.pickle\", \"rb\"))\n",
    "sdcnl_highest_list_ready = sdcnl_highest_list_ready[['text', 'highest', 'is_suicide']]\n",
    "sdcnl_highest_list_ready.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [13:39<00:00, 24.41it/s]\n"
     ]
    }
   ],
   "source": [
    "twitter = pd.read_csv('../../corpus/mental-health-twitter.csv')\n",
    "twitter = twitter[[\"post_text\",\"label\"]]\n",
    "sentence_list = twitter['post_text'].tolist()\n",
    "mbti_df_list = convert_mbti_list(sentence_list)\n",
    "twitter_ready = pd.concat([twitter, mbti_df_list], axis=1)\n",
    "twitter_ready.head()\n",
    "save_dataset(twitter_ready, \"../../corpus/personality-aware-depression\", \"albert-base-list-twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_highest_list_ready = pd.concat([twitter_ready['post_text'], mbti_df_list[\"highest\"]], axis=1)\n",
    "twitter_highest_list_ready['E'] = twitter_highest_list_ready['highest'].str.contains('E').astype(int)\n",
    "twitter_highest_list_ready['F'] = twitter_highest_list_ready['highest'].str.contains('F').astype(int)\n",
    "twitter_highest_list_ready['N'] = twitter_highest_list_ready['highest'].str.contains('N').astype(int)\n",
    "twitter_highest_list_ready['J'] = twitter_highest_list_ready['highest'].str.contains('J').astype(int)\n",
    "twitter_highest_list_ready.drop(\"highest\", axis=1, inplace=True)\n",
    "save_dataset(twitter_highest_list_ready, \"../../corpus/personality-aware-depression\", \"albert-base-highest-twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
