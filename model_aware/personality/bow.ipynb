{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"svZDc901sR6B"},"source":["# Part 1: Environment Setup"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48678,"status":"ok","timestamp":1675262538307,"user":{"displayName":"Jing Jie Tan","userId":"03707089291343328550"},"user_tz":-480},"id":"agfLJCHh46Jt","outputId":"3c33a3bc-711d-44f3-d997-f7f06202e671"},"outputs":[],"source":["import os\n","os.getcwd()\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from IPython.display import display\n","import pickle\n","import sys\n","import torch\n","import torch.nn as nn\n","sys.path.append(\"..\")\n","def extract(path):\n","    print(os.getcwd())\n","    file = open(path, 'rb')\n","    object_file = pickle.load(file)\n","    file.close()\n","    return object_file\n","\n","def save_dataset(item, dir, name):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","    path = dir+\"/\"+name+\".pickle\"\n","    pickle.dump(item, open(path, 'wb'))\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import re\n","def clear_text(data):\n","    cleaned_text=[]\n","    for sentence in data:\n","        sentence=sentence.lower()\n","        # removing links from text data\n","        sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n","    \n","        # removing other symbols\n","        sentence=re.sub('[^0-9a-z]',' ',sentence)\n","        cleaned_text.append(sentence)\n","    return cleaned_text"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def expand(np_data):\n","    temp=[]\n","    for i in range(len(np_data)):\n","        temp.append(np.array(np_data[i]))\n","    return temp"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/jingjietan/Desktop/PRaware/model_aware/personality\n"]}],"source":["class Lemmatizer(object):\n","    def __init__(self):\n","        self.lemmatizer = WordNetLemmatizer()\n","    def __call__(self, sentence):\n","        return [self.lemmatizer.lemmatize(word) for word in sentence.split() if len(word)>2]\n","\n","vectorizer_mbti=extract('./bow/mbti_vectorizer.pickle')"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# # Part 3 Model Training\n","class CustomNetwork(nn.Module):\n","    def __init__(self, input_size):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_size, 5)\n","        self.fc2 = nn.Linear(5, 5)\n","        self.fc3 = nn.Linear(5, 1)\n","        \n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.sigmoid(self.fc3(x))\n","        return x\n","    \n","def personality_inference(network, series_data):\n","    predictions = []\n","\n","    for item in series_data:\n","        # Convert the item to a tensor and perform necessary preprocessing\n","        tensor_item = torch.tensor(item).type(torch.FloatTensor)\n","        tensor_item = tensor_item.to(\"mps\")\n","\n","        # Forward pass through your network\n","        outs = network(tensor_item)\n","        outs = outs.view(-1)\n","        \n","        # Apply the threshold (0.5 in your case) to get binary predictions\n","        preds = outs > 0.5\n","\n","        # Append the prediction to the list\n","        preds = preds.cpu().numpy()\n","        predictions.append(preds)\n","    \n","    return predictions\n"]},{"cell_type":"markdown","metadata":{},"source":["# sentiment"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["O\n","C\n","E\n","A\n"]}],"source":["imdb_dataset = pd.read_csv('../../corpus/imdb.csv')\n","imdb_dataset['sentiment'] = imdb_dataset['sentiment'].map({'positive': 1, 'negative': 0})\n","imdb_dataset.review = clear_text(imdb_dataset.review)\n","# use vectorizer_mbti process the review and the content into another column('bow')\n","imdb_dataset['bow'] = expand(vectorizer_mbti.transform(imdb_dataset.review).toarray())\n","for dimension in ['O','C','E','A']:\n","    print(dimension)\n","    network = torch.load('./bow/'+dimension+'.pt')\n","    network.eval()\n","    imdb_dataset[dimension] = personality_inference(network, imdb_dataset[\"bow\"])\n","# make True to 1 and False to 0\n","for dimension in ['O','C','E','A']:\n","    imdb_dataset[dimension] = imdb_dataset[dimension].apply(lambda x: 1 if x else 0)\n","imdb_dataset = imdb_dataset.drop(columns=['bow'])\n","save_dataset(imdb_dataset, \"../../corpus/personality-aware-sentiment\", \"bow-imdb\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["O\n","C\n","E\n","A\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>label</th>\n","      <th>O</th>\n","      <th>C</th>\n","      <th>E</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bad   bad    bad    that one word seems to pre...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>isn t it the ultimate sign of a movie s cinema...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gordy   is not a movie   it is a 90 minute ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>disconnect the phone line    don t accept the ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>when robert forster found himself famous again...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             content  label  O  C  E  A\n","0  bad   bad    bad    that one word seems to pre...      0  1  0  1  1\n","1  isn t it the ultimate sign of a movie s cinema...      0  1  1  0  1\n","2     gordy   is not a movie   it is a 90 minute ...      0  1  1  0  0\n","3  disconnect the phone line    don t accept the ...      0  0  1  0  1\n","4  when robert forster found himself famous again...      0  0  0  0  1"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["moviereview_dataset = pd.read_csv('../../corpus/movie-review.csv')\n","moviereview_dataset.content = clear_text(moviereview_dataset.content)\n","# use vectorizer_mbti process the review and the content into another column('bow')\n","moviereview_dataset['bow'] = expand(vectorizer_mbti.transform(moviereview_dataset.content).toarray())\n","for dimension in ['O','C','E','A']:\n","    print(dimension)\n","    network = torch.load('./bow/'+dimension+'.pt')\n","    network.eval()\n","    moviereview_dataset[dimension] = personality_inference(network, moviereview_dataset[\"bow\"])\n","\n","# make True to 1 and False to 0\n","for dimension in ['O','C','E','A']:\n","    moviereview_dataset[dimension] = moviereview_dataset[dimension].apply(lambda x: 1 if x else 0)\n","moviereview_dataset = moviereview_dataset.drop(columns=['bow'])\n","\n","save_dataset(moviereview_dataset, \"../../corpus/personality-aware-sentiment\", \"bow-movie-review\")\n","moviereview_dataset.head()"]},{"cell_type":"markdown","metadata":{},"source":["# depression"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset.text = clear_text(sdcnl_dataset.text)\n","/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset['bow'] = expand(vectorizer_mbti.transform(sdcnl_dataset.text).toarray())\n"]},{"name":"stdout","output_type":"stream","text":["O\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset[dimension] = personality_inference(network, sdcnl_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["C\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset[dimension] = personality_inference(network, sdcnl_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["E\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset[dimension] = personality_inference(network, sdcnl_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["A\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset[dimension] = personality_inference(network, sdcnl_dataset[\"bow\"])\n","/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/351508845.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sdcnl_dataset[dimension] = sdcnl_dataset[dimension].apply(lambda x: 1 if x else 0)\n"]}],"source":["sdcnl = pd.read_csv('../../corpus/sdcnl.csv')\n","\n","# merge title and selftext column together, both have string value\n","sdcnl['text'] = sdcnl['title'].astype(str) + \" | \" + sdcnl['selftext'].astype(str)\n","\n","# drop all column except text and is_suicide column\n","sdcnl_dataset = sdcnl[['text', 'is_suicide']]\n","\n","sdcnl_dataset.text = clear_text(sdcnl_dataset.text)\n","# use vectorizer_mbti process the review and the content into another column('bow')\n","sdcnl_dataset['bow'] = expand(vectorizer_mbti.transform(sdcnl_dataset.text).toarray())\n","for dimension in ['O','C','E','A']:\n","    print(dimension)\n","    network = torch.load('./bow/'+dimension+'.pt')\n","    network.eval()\n","    sdcnl_dataset[dimension] = personality_inference(network, sdcnl_dataset[\"bow\"])\n","# make True to 1 and False to 0\n","for dimension in ['O','C','E','A']:\n","    sdcnl_dataset[dimension] = sdcnl_dataset[dimension].apply(lambda x: 1 if x else 0)\n","sdcnl_dataset = sdcnl_dataset.drop(columns=['bow'])\n","save_dataset(sdcnl_dataset, \"../../corpus/personality-aware-depression\", \"bow-sdcnl\")"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset.post_text = clear_text(twitter_dataset.post_text)\n","/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset['bow'] = expand(vectorizer_mbti.transform(twitter_dataset.post_text).toarray())\n"]},{"name":"stdout","output_type":"stream","text":["O\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset[dimension] = personality_inference(network, twitter_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["C\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset[dimension] = personality_inference(network, twitter_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["E\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset[dimension] = personality_inference(network, twitter_dataset[\"bow\"])\n"]},{"name":"stdout","output_type":"stream","text":["A\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset[dimension] = personality_inference(network, twitter_dataset[\"bow\"])\n","/var/folders/ls/gq94l83s5gn947dpv5ks7p980000gn/T/ipykernel_27900/50979305.py:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  twitter_dataset[dimension] = twitter_dataset[dimension].apply(lambda x: 1 if x else 0)\n"]}],"source":["twitter = pd.read_csv('../../corpus/Mental-Health-Twitter.csv')\n","# drop all column except text and is_suicide column\n","twitter_dataset = twitter[['post_text', 'label']]\n","\n","twitter_dataset.post_text = clear_text(twitter_dataset.post_text)\n","# use vectorizer_mbti process the review and the content into another column('bow')\n","twitter_dataset['bow'] = expand(vectorizer_mbti.transform(twitter_dataset.post_text).toarray())\n","for dimension in ['O','C','E','A']:\n","    print(dimension)\n","    network = torch.load('./bow/'+dimension+'.pt')\n","    network.eval()\n","    twitter_dataset[dimension] = personality_inference(network, twitter_dataset[\"bow\"])\n","# make True to 1 and False to 0\n","for dimension in ['O','C','E','A']:\n","    twitter_dataset[dimension] = twitter_dataset[dimension].apply(lambda x: 1 if x else 0)\n","twitter_dataset = twitter_dataset.drop(columns=['bow'])\n","save_dataset(twitter_dataset, \"../../corpus/personality-aware-depression\", \"bow-twitter\")"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>post_text</th>\n","      <th>label</th>\n","      <th>O</th>\n","      <th>C</th>\n","      <th>E</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>it s just over 2 years since i was diagnosed w...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>it s sunday  i need a break  so i m planning t...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>awake but tired  i need to sleep but my brain ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rt  sewhq   retro bears make perfect gifts and...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>it s hard to say whether packing lists are mak...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           post_text  label  O  C  E  A\n","0  it s just over 2 years since i was diagnosed w...      1  1  1  1  1\n","1  it s sunday  i need a break  so i m planning t...      1  0  0  1  1\n","2  awake but tired  i need to sleep but my brain ...      1  1  0  1  0\n","3  rt  sewhq   retro bears make perfect gifts and...      1  0  1  1  1\n","4  it s hard to say whether packing lists are mak...      1  0  1  1  1"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["twitter_dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
