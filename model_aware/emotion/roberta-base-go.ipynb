{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas pickle file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "def extract(path):\n",
    "    print(os.getcwd())\n",
    "    file = open(path, 'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    file.close()\n",
    "    return object_file\n",
    "\n",
    "def save_dataset(item, dir, name):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    path = dir+\"/\"+name+\".pickle\"\n",
    "    pickle.dump(item, open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 2/2 [00:00<00:00, 23.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        joy   neutral  approval    relief  admiration  excitement  gratitude  \\\n",
      "0  0.895246  0.035179  0.028167  0.026642    0.020664    0.016066   0.015526   \n",
      "1  0.002303  0.963529  0.014937  0.000378    0.003578    0.002336   0.001188   \n",
      "\n",
      "     caring  amusement      love  ...    desire  disappointment  curiosity  \\\n",
      "0  0.014913   0.013467  0.012827  ...  0.002370        0.002130   0.001743   \n",
      "1  0.001146   0.001991  0.001160  ...  0.000982        0.002786   0.001232   \n",
      "\n",
      "   nervousness  surprise   remorse     grief  embarrassment      fear  \\\n",
      "0     0.001603  0.001498  0.001199  0.001178       0.000986  0.000782   \n",
      "1     0.000328  0.000820  0.000313  0.000402       0.000548  0.001327   \n",
      "\n",
      "    disgust  \n",
      "0  0.000671  \n",
      "1  0.001774  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None, max_length=512)\n",
    "\n",
    "def convert_list_to_dict(list_of_dicts):\n",
    "    result_dict = {}\n",
    "    for item in list_of_dicts:\n",
    "        label = item.get(\"label\")\n",
    "        score = item.get(\"score\")\n",
    "        if label is not None and score is not None:\n",
    "            result_dict[label] = score\n",
    "    return result_dict\n",
    "\n",
    "def convert_emotion(sentences):\n",
    "    # Assuming classifier and convert_list_to_dict are defined elsewhere\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Process each sentence in the list\n",
    "    for sentence in tqdm(sentences):\n",
    "        emo = classifier(sentence)  # Assuming classifier returns emotions for a single sentence\n",
    "        out = convert_list_to_dict(emo[0])  # Assuming convert_list_to_dict processes the emotion list\n",
    "        df = pd.DataFrame(out, index=[0])\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate the list of DataFrames into a single DataFrame\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "print(convert_emotion([\"I am happy\",\"he\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8675/8675 [49:00<00:00,  2.95it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "mbti = pd.read_csv('../../corpus/mbti.csv')\n",
    "sentence_list = mbti['posts'].tolist()\n",
    "emotion_df_list = convert_emotion(sentence_list)\n",
    "mbti_ready = pd.concat([mbti, emotion_df_list], axis=1)\n",
    "mbti_ready.head()\n",
    "save_dataset(mbti_ready, \"../../corpus/emotion-aware-personality\", \"roberta-base-mbti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset = extract(\"../../corpus/emotion-aware-personality/roberta-base-mbti.pickle\")\n",
    "\n",
    "\n",
    "dataset[\"E\"] = dataset['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
    "dataset[\"O\"] = dataset['type'].apply(lambda x: 1 if x[1] == 'N' else 0)\n",
    "dataset[\"A\"] = dataset['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
    "dataset[\"C\"] = dataset['type'].apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "\n",
    "dataset = dataset.drop(['type'], axis=1)\n",
    "\n",
    "#save\n",
    "save_dataset(dataset, \"../../corpus/emotion-aware-personality\", \"roberta-base-mbti\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [2:39:10<00:00,  5.24it/s]  \n"
     ]
    }
   ],
   "source": [
    "imdb = pd.read_csv('../../corpus/imdb.csv')\n",
    "imdb['sentiment'] = imdb['sentiment'].replace('positive', 1)\n",
    "imdb['sentiment'] = imdb['sentiment'].replace('negative', 0)\n",
    "sentence_list = imdb['review'].tolist()\n",
    "emotion_df_list = convert_emotion(sentence_list)\n",
    "imdb_ready = pd.concat([imdb, emotion_df_list], axis=1)\n",
    "save_dataset(imdb_ready, \"../../corpus/emotion-aware-sentiment\", \"roberta-base-imdb.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:26<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "moviereview = pd.read_csv('../../corpus/movie-review.csv')\n",
    "sentence_list = moviereview['content'].tolist()\n",
    "emotion_df_list = convert_emotion(sentence_list)\n",
    "moviereview_ready = pd.concat([moviereview, emotion_df_list], axis=1)\n",
    "save_dataset(moviereview_ready, \"../../corpus/emotion-aware-sentiment\", \"roberta-base-moviereview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1895/1895 [05:30<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "sdcnl = pd.read_csv('../../corpus/sdcnl.csv')\n",
    "\n",
    "# merge title and selftext column together, both have string value\n",
    "sdcnl['text'] = sdcnl['title'].astype(str) + \" | \" + sdcnl['selftext'].astype(str)\n",
    "\n",
    "# drop all column except text and is_suicide column\n",
    "sdcnl = sdcnl[['text', 'is_suicide']]\n",
    "\n",
    "sdcnl.head()\n",
    "\n",
    "sentence_list = sdcnl['text'].tolist()\n",
    "emotion_df_list = convert_emotion(sentence_list)\n",
    "sdcnl_ready = pd.concat([sdcnl, emotion_df_list], axis=1)\n",
    "sdcnl_ready.head()\n",
    "save_dataset(sdcnl_ready, \"../../corpus/emotion-aware-depression\", \"roberta-base-sdcnl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [22:53<00:00, 14.56it/s]\n"
     ]
    }
   ],
   "source": [
    "twitter = pd.read_csv('../../corpus/mental-health-twitter.csv')\n",
    "twitter = twitter[[\"post_text\",\"label\"]]\n",
    "sentence_list = twitter['post_text'].tolist()\n",
    "emotion_df_list = convert_emotion(sentence_list)\n",
    "twitter_ready = pd.concat([twitter, emotion_df_list], axis=1)\n",
    "twitter_ready.head()\n",
    "save_dataset(twitter_ready, \"../../corpus/emotion-aware-depression\", \"roberta-base-twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
